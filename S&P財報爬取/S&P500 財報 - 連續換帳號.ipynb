{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.rocketfinancial.com/Dashboard.aspx?pID=0\")\n",
    "url = driver.current_url\n",
    "url = url.replace(\"Dashboard.aspx?pID=0\", \"Login.aspx\")\n",
    "driver.get(url)\n",
    "driver.find_element_by_name(\"username\").send_keys(\"Tsao0919_100\")\n",
    "driver.find_element_by_name(\"password\").send_keys(\"asdf30295789\")\n",
    "driver.find_element_by_name(\"btnLogin\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RHI ROK COL ROP ROST RCL SPGI CRM SBAC SCG SLB STX SEE SRE SHW SPG SWKS SLG SNA SO LUV SWK SBUX STT SRCL SYK STI SIVB SYMC SYF SNPS SYY TROW TTWO TPR TGT TEL FTI TXN TXT BK CLX COO HSY MOS TRV DIS TMO TIF TWX TJX TMK TSS TSCO TDG TRIP FOXA FOX TSN USB UDR ULTA UAA UA UNP UAL UNH UPS URI UTX UHS UNM VFC VLO VAR VTR VRSN VRSK VZ VRTX VIAB V VNO VMC WMT WBA WM WAT WEC WFC WELL WDC WU WRK WY WHR WMB WLTW WYN WYNN XEL XRX XLNX XL XYL YUM ZBH ZION ZTS\n"
     ]
    }
   ],
   "source": [
    "##股池\n",
    "Stocklist = [i for i in input().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "AccountCumulated = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in Stocklist:\n",
    "    if count == 12:\n",
    "        driver.get(\"https://www.rocketfinancial.com/Dashboard.aspx?pID=0\")\n",
    "        url = driver.current_url\n",
    "        url = url.replace(\"Dashboard.aspx?pID=0\", \"Login.aspx\")\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_name(\"username\").send_keys(\"Tsao0919_{}\".format(AccountCumulated))\n",
    "        driver.find_element_by_name(\"password\").send_keys(\"asdf30295789\")\n",
    "        driver.find_element_by_name(\"btnLogin\").click()\n",
    "        time.sleep(5)\n",
    "        driver.find_element_by_class_name(\"searchWatermark\").send_keys(stock)\n",
    "        driver.find_element_by_id(\"ctrlHeader_searchBar_txtSearch\").send_keys(Keys.ENTER)\n",
    "        url = driver.current_url\n",
    "        url = url.replace(\"Overview\", \"Financials\")\n",
    "        url = url + \"&rID=1&stID=3\"\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        header = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "          \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "        r = req.get(url, headers=header)\n",
    "        count = 0\n",
    "        AccountCumulated += 1\n",
    "        ########IncomeStatement 1#########\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\IncomeStatement\\{}_Income_Statement.csv'.format(stock), encoding='utf-8', index=False)\n",
    "        except:\n",
    "            print(\"No data\")\n",
    "        #######IncomeStatement 結束#######\n",
    "        url2 = url.replace(\"&rID=1&stID=3\", \"&rID=2\")\n",
    "        driver.get(url2) \n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        ######BalanceSheet 1###########\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\BalanceSheet\\{}_Balance_Sheets.csv'.format(stock), encoding='utf-8', index=False)\n",
    "        except:\n",
    "            print(\"no data\")\n",
    "        ######BalanceSheet 結束##########\n",
    "        url3 = url2.replace(\"&rID=2\", \"&rID=3\")\n",
    "        driver.get(url3)\n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        #####CashFlow Statement 1#######\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\CashFlowStatement\\{}_CashFlow_Statements.csv'.format(stock), encoding='utf-8', index=False)\n",
    "                count += 1\n",
    "        except:\n",
    "            print(\"no data\")\n",
    "    else:\n",
    "        driver.find_element_by_class_name(\"searchWatermark\").send_keys(stock)\n",
    "        driver.find_element_by_id(\"ctrlHeader_searchBar_txtSearch\").send_keys(Keys.ENTER)\n",
    "        url = driver.current_url\n",
    "        url = url.replace(\"Overview\", \"Financials\")\n",
    "        url = url + \"&rID=1&stID=3\"\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        header = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "          \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "        r = req.get(url, headers=header)\n",
    "        ########IncomeStatement 1#########\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\IncomeStatement\\{}_Income_Statement.csv'.format(stock), encoding='utf-8', index=False)\n",
    "        except:\n",
    "            print(\"No data\")\n",
    "        #######IncomeStatement 結束#######\n",
    "        url2 = url.replace(\"&rID=1&stID=3\", \"&rID=2\")\n",
    "        driver.get(url2) \n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        ######BalanceSheet 1###########\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\BalanceSheet\\{}_Balance_Sheets.csv'.format(stock), encoding='utf-8', index=False)\n",
    "        except:\n",
    "            print(\"no data\")\n",
    "        ######BalanceSheet 結束##########\n",
    "        url3 = url2.replace(\"&rID=2\", \"&rID=3\")\n",
    "        driver.get(url3)\n",
    "        driver.find_element_by_id(\"ctrlPeriodBar_Quarterly\").click()\n",
    "        #####CashFlow Statement 1#######\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            for block in soup.find_all('table',{'class':'gridView'}):\n",
    "                da = block.find_all('tr')\n",
    "                append_row = {}\n",
    "                col=[]\n",
    "                for i in (da[0].find_all('th')):\n",
    "                    col.append((i.text))\n",
    "\n",
    "                df = pd.DataFrame(columns=col)\n",
    "                for s in range(1, len(da)):\n",
    "                    ind={}\n",
    "                    z = da[0].find_all('th')\n",
    "                    p = da[s].find_all('td')\n",
    "                    for m in range(len(p)):\n",
    "                        ind['{}'.format(z[m].text)] = p[m].text\n",
    "                    df = df.append(ind, ignore_index=True)\n",
    "\n",
    "                df.to_csv(r'C:\\Users\\a0971\\Documents\\project_CTBC\\S&P500\\CashFlowStatement\\{}_CashFlow_Statements.csv'.format(stock), encoding='utf-8', index=False)\n",
    "                count += 1\n",
    "        except:\n",
    "            print(\"no data\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
